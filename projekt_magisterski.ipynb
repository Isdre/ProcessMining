{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tbJIQIsoDW8"
   },
   "source": [
    "# $\\Huge Projekt$  $\\Huge dyplomowy$\n",
    "\n",
    "\n",
    "$\\Large J.$  $\\Large Witek$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fiidqG_qn48p"
   },
   "source": [
    "# **Cel projektu**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y-edynjDofvj"
   },
   "source": [
    "Celem pracy jest porównanie istniejących algorytmów generujących model procesu na podstawie informacji wydobytych z logów systemowych. Opierając się na wybranym algorytmie, przedstawiono metodę przekształcającą wygenerowany model procesu do postaci równoważnej specyfikacji logicznej. Praca skupia się w szczególności na modelu procesu przedstawionym w notacji drzewa procesu, ze względu na jego prostą strukturę oraz gwarancję poprawności. Dodatkowym celem pracy jest weryfikacja wytworzonych specyfikacji logicznych przy użyciu systemów automatycznego dowodzenia twierdzeń logicznych dla logiki pierwszego rzędu. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C5emQAaxpOI-"
   },
   "source": [
    "# **Przygotowanie środowiska**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wdGeNMCKtqxN"
   },
   "source": [
    "## **Instalacja bibliotek**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8Sj2SMbTf_MP",
    "ExecuteTime": {
     "end_time": "2024-12-04T21:21:33.963012Z",
     "start_time": "2024-12-04T21:21:33.087858Z"
    }
   },
   "source": [
    "%pip install pm4py==2.7.4"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active code page: 1250\n",
      "Requirement already satisfied: pm4py==2.7.4 in d:\\jetbrains\\projects\\studioproject\\.venv\\lib\\site-packages (2.7.4)\n",
      "Requirement already satisfied: deprecation in d:\\jetbrains\\projects\\studioproject\\.venv\\lib\\site-packages (from pm4py==2.7.4) (2.1.0)\n",
      "Requirement already satisfied: graphviz in d:\\jetbrains\\projects\\studioproject\\.venv\\lib\\site-packages (from pm4py==2.7.4) (0.20.3)\n",
      "Requirement already satisfied: intervaltree in d:\\jetbrains\\projects\\studioproject\\.venv\\lib\\site-packages (from pm4py==2.7.4) (3.1.0)\n",
      "Requirement already satisfied: lxml in d:\\jetbrains\\projects\\studioproject\\.venv\\lib\\site-packages (from pm4py==2.7.4) (5.3.0)\n",
      "Requirement already satisfied: matplotlib in d:\\jetbrains\\projects\\studioproject\\.venv\\lib\\site-packages (from pm4py==2.7.4) (3.9.2)\n",
      "Requirement already satisfied: networkx in d:\\jetbrains\\projects\\studioproject\\.venv\\lib\\site-packages (from pm4py==2.7.4) (3.4.2)\n",
      "Requirement already satisfied: numpy in d:\\jetbrains\\projects\\studioproject\\.venv\\lib\\site-packages (from pm4py==2.7.4) (2.1.3)\n",
      "Requirement already satisfied: pandas in d:\\jetbrains\\projects\\studioproject\\.venv\\lib\\site-packages (from pm4py==2.7.4) (2.2.3)\n",
      "Requirement already satisfied: pydotplus in d:\\jetbrains\\projects\\studioproject\\.venv\\lib\\site-packages (from pm4py==2.7.4) (2.0.2)\n",
      "Requirement already satisfied: pytz in d:\\jetbrains\\projects\\studioproject\\.venv\\lib\\site-packages (from pm4py==2.7.4) (2024.2)\n",
      "Requirement already satisfied: scipy in d:\\jetbrains\\projects\\studioproject\\.venv\\lib\\site-packages (from pm4py==2.7.4) (1.14.1)\n",
      "Requirement already satisfied: stringdist in d:\\jetbrains\\projects\\studioproject\\.venv\\lib\\site-packages (from pm4py==2.7.4) (1.0.9)\n",
      "Requirement already satisfied: tqdm in d:\\jetbrains\\projects\\studioproject\\.venv\\lib\\site-packages (from pm4py==2.7.4) (4.67.1)\n",
      "Requirement already satisfied: cvxopt in d:\\jetbrains\\projects\\studioproject\\.venv\\lib\\site-packages (from pm4py==2.7.4) (1.3.2)\n",
      "Requirement already satisfied: packaging in d:\\jetbrains\\projects\\studioproject\\.venv\\lib\\site-packages (from deprecation->pm4py==2.7.4) (24.2)\n",
      "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in d:\\jetbrains\\projects\\studioproject\\.venv\\lib\\site-packages (from intervaltree->pm4py==2.7.4) (2.4.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\jetbrains\\projects\\studioproject\\.venv\\lib\\site-packages (from matplotlib->pm4py==2.7.4) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\jetbrains\\projects\\studioproject\\.venv\\lib\\site-packages (from matplotlib->pm4py==2.7.4) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\jetbrains\\projects\\studioproject\\.venv\\lib\\site-packages (from matplotlib->pm4py==2.7.4) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in d:\\jetbrains\\projects\\studioproject\\.venv\\lib\\site-packages (from matplotlib->pm4py==2.7.4) (1.4.7)\n",
      "Requirement already satisfied: pillow>=8 in d:\\jetbrains\\projects\\studioproject\\.venv\\lib\\site-packages (from matplotlib->pm4py==2.7.4) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\jetbrains\\projects\\studioproject\\.venv\\lib\\site-packages (from matplotlib->pm4py==2.7.4) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\jetbrains\\projects\\studioproject\\.venv\\lib\\site-packages (from matplotlib->pm4py==2.7.4) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\jetbrains\\projects\\studioproject\\.venv\\lib\\site-packages (from pandas->pm4py==2.7.4) (2024.2)\n",
      "Requirement already satisfied: colorama in d:\\jetbrains\\projects\\studioproject\\.venv\\lib\\site-packages (from tqdm->pm4py==2.7.4) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in d:\\jetbrains\\projects\\studioproject\\.venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->pm4py==2.7.4) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "o2zJkAdb-SOx",
    "ExecuteTime": {
     "end_time": "2024-12-04T21:21:33.994043Z",
     "start_time": "2024-12-04T21:21:33.964013Z"
    }
   },
   "source": [
    "!apt install libgraphviz-dev"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active code page: 1250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'apt' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_c2OhxSx-WuD",
    "ExecuteTime": {
     "end_time": "2024-12-04T21:21:39.608151Z",
     "start_time": "2024-12-04T21:21:33.995044Z"
    }
   },
   "source": [
    "!pip install pygraphviz"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active code page: 1250\n",
      "Collecting pygraphviz\n",
      "  Downloading pygraphviz-1.14.tar.gz (106 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: pygraphviz\n",
      "  Building wheel for pygraphviz (pyproject.toml): started\n",
      "  Building wheel for pygraphviz (pyproject.toml): finished with status 'error'\n",
      "Failed to build pygraphviz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Building wheel for pygraphviz (pyproject.toml) did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [54 lines of output]\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\\lib.win-amd64-cpython-310\\pygraphviz\n",
      "  copying pygraphviz\\agraph.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\n",
      "  copying pygraphviz\\graphviz.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\n",
      "  copying pygraphviz\\scraper.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\n",
      "  copying pygraphviz\\testing.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\n",
      "  copying pygraphviz\\__init__.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\n",
      "  creating build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_attribute_defaults.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_clear.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_close.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_drawing.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_edge_attributes.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_graph.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_html.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_layout.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_node_attributes.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_readwrite.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_repr_mimebundle.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_scraper.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_string.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_subgraph.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\test_unicode.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  copying pygraphviz\\tests\\__init__.py -> build\\lib.win-amd64-cpython-310\\pygraphviz\\tests\n",
      "  running egg_info\n",
      "  writing pygraphviz.egg-info\\PKG-INFO\n",
      "  writing dependency_links to pygraphviz.egg-info\\dependency_links.txt\n",
      "  writing top-level names to pygraphviz.egg-info\\top_level.txt\n",
      "  reading manifest file 'pygraphviz.egg-info\\SOURCES.txt'\n",
      "  reading manifest template 'MANIFEST.in'\n",
      "  warning: no files found matching '*.swg'\n",
      "  warning: no files found matching '*.png' under directory 'doc'\n",
      "  warning: no files found matching '*.html' under directory 'doc'\n",
      "  warning: no files found matching '*.txt' under directory 'doc'\n",
      "  warning: no files found matching '*.css' under directory 'doc'\n",
      "  warning: no previously-included files matching '*~' found anywhere in distribution\n",
      "  warning: no previously-included files matching '*.pyc' found anywhere in distribution\n",
      "  warning: no previously-included files matching '.svn' found anywhere in distribution\n",
      "  no previously-included directories found matching 'doc\\build'\n",
      "  adding license file 'LICENSE'\n",
      "  writing manifest file 'pygraphviz.egg-info\\SOURCES.txt'\n",
      "  copying pygraphviz\\graphviz.i -> build\\lib.win-amd64-cpython-310\\pygraphviz\n",
      "  copying pygraphviz\\graphviz_wrap.c -> build\\lib.win-amd64-cpython-310\\pygraphviz\n",
      "  running build_ext\n",
      "  building 'pygraphviz._graphviz' extension\n",
      "  creating build\\temp.win-amd64-cpython-310\\Release\\pygraphviz\n",
      "  \"D:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.41.34120\\bin\\HostX86\\x64\\cl.exe\" /c /nologo /O2 /W3 /GL /DNDEBUG /MD -DSWIG_PYTHON_STRICT_BYTE_CHAR -DGVDLL -ID:\\JetBrains\\Projects\\StudioProject\\.venv\\include -IC:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\include -IC:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python310\\Include \"-ID:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Tools\\MSVC\\14.41.34120\\include\" \"-ID:\\Program Files\\Microsoft Visual Studio\\2022\\Community\\VC\\Auxiliary\\VS\\include\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\include\\10.0.22621.0\\ucrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\um\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\shared\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\winrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\10\\\\include\\10.0.22621.0\\\\cppwinrt\" \"-IC:\\Program Files (x86)\\Windows Kits\\NETFXSDK\\4.8\\include\\um\" /Tcpygraphviz/graphviz_wrap.c /Fobuild\\temp.win-amd64-cpython-310\\Release\\pygraphviz/graphviz_wrap.obj\n",
      "  graphviz_wrap.c\n",
      "  pygraphviz/graphviz_wrap.c(9): warning C4005: 'SWIG_PYTHON_STRICT_BYTE_CHAR': macro redefinition\n",
      "  pygraphviz/graphviz_wrap.c(9): note: 'SWIG_PYTHON_STRICT_BYTE_CHAR' previously declared on the command line\n",
      "  pygraphviz/graphviz_wrap.c(3023): fatal error C1083: Cannot open include file: 'graphviz/cgraph.h': No such file or directory\n",
      "  error: command 'D:\\\\Program Files\\\\Microsoft Visual Studio\\\\2022\\\\Community\\\\VC\\\\Tools\\\\MSVC\\\\14.41.34120\\\\bin\\\\HostX86\\\\x64\\\\cl.exe' failed with exit code 2\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for pygraphviz\n",
      "ERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (pygraphviz)\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8rx20JGjtO95"
   },
   "source": [
    "## **Importy**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MPd_KPcys8Cg",
    "ExecuteTime": {
     "end_time": "2024-12-04T21:21:39.623382Z",
     "start_time": "2024-12-04T21:21:39.609152Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pm4py\n",
    "import re\n",
    "import json\n",
    "\n",
    "from functools import reduce\n",
    "from itertools import groupby\n",
    "from itertools import chain\n",
    "from more_itertools import pairwise\n",
    "from collections import Counter\n",
    "import pygraphviz as pgv\n",
    "from IPython.display import Image, display\n",
    "from datetime import datetime\n"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'more_itertools'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 10\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mitertools\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m groupby\n\u001B[0;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mitertools\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m chain\n\u001B[1;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmore_itertools\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m pairwise\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcollections\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Counter\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpygraphviz\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpgv\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'more_itertools'"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "b3b76U7szmyB"
   },
   "source": [
    "# EXAMPLE 1\n",
    "log_1 = pm4py.read_xes(\"running-example.xes\")\n",
    "\n",
    "# EXAMPLE 2\n",
    "log_2 = pm4py.format_dataframe(pd.read_csv(\"repairExample.csv\", sep=','),\n",
    "                                   case_id='Case ID', activity_key='Activity',timestamp_key='Start Timestamp')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24TpQ5wXs_1n"
   },
   "source": [
    "# **Dziennik zdarzeń**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4flbV-jJnw1q"
   },
   "source": [
    "Dane wejściowe do odkrycia procesu przechowywane są w dzienniku zdarzeń. W dzienniku zdarzeń możemy zwykle znaleźć wiele atrybutów, jednak większość algorytmów wykorzystywanych w eksploracji procesów potrzebuje trzech: identyfikatora przypadku, śladu czasu oraz nazwy samej czynności."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "gTEc05xS1kd2",
    "outputId": "3a69ecb2-2cbf-4c24-e4cb-670dfc829a45"
   },
   "source": [
    "log_1.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4Mnuz_KZ1vOP",
    "outputId": "81d63c5c-11a6-45c2-c080-549ce39e4771"
   },
   "source": [
    "log_1.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 377
    },
    "id": "ShvOOuVv1ok3",
    "outputId": "5a6c718f-3670-40c6-fbfd-8fb4f975f43e"
   },
   "source": [
    "log_2.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vTtfZw6Y1yYN",
    "outputId": "d115a868-c06e-4412-c522-c33c4a59f275"
   },
   "source": [
    "log_2.shape"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOeck72F18Ik"
   },
   "source": [
    "Zdarzenia występujące w dzienniku możemy pogrupować w obrębie jednego przypadku, a następnie na podstawie czasu początkowego stworzyć grupy będące tzw. śladami, które można zliczyć. Taka operacja pozwoli nam na identyfikacje wszystkich możliwych śladów."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "JKbZUbVA16xy",
    "outputId": "466c608f-9640-4373-ca2d-9a44c632c9b5"
   },
   "source": [
    "# EXAMPLE 1\n",
    "\n",
    "#Routes discover\n",
    "log_1_routes = (log_1\n",
    "    .sort_values(by=['case:concept:name','time:timestamp'])\n",
    "    .groupby(['case:concept:name'])\n",
    "    .agg({'Activity': ';'.join})\n",
    ")\n",
    "\n",
    "#Routes counter\n",
    "log_1_routes['count'] = 0\n",
    "\n",
    "log_1_routes = (log_1_routes.groupby('Activity', as_index = False).count().sort_values(['count'], ascending = False).reset_index(drop=True))\n",
    "log_1_routes.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "TpiLg7Ki2Kc1",
    "outputId": "c9725be1-e851-47c0-93ba-bb18282242c6"
   },
   "source": [
    "# EXAMPLE 2\n",
    "\n",
    "#Routes discover\n",
    "log_2['Start Timestamp'] = pd.to_datetime(log_2['Start Timestamp'])\n",
    "\n",
    "\n",
    "log_2_routes = (log_2\n",
    "    .sort_values(by=['Case ID','Start Timestamp'])\n",
    "    .groupby(['Case ID'])\n",
    "    .agg({'Activity': ';'.join})\n",
    ")\n",
    "\n",
    "#Routes counter\n",
    "log_2_routes['count'] = 0\n",
    "log_2_routes = (log_2_routes.groupby('Activity', as_index = False).count().sort_values(['count'], ascending = False).reset_index(drop=True))\n",
    "log_2_routes.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xV_tQYAWsNz0"
   },
   "source": [
    "## **Graf bezpośrednich podążeń**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZ8cSSG73bT8"
   },
   "source": [
    "W grafie bezpośrednich podążeń wierzchołki odpowiadają zadaniom, a krawędzie odpowiadają relacji bezpośredniego podążania. Bezpośrednie podążanie oznacza wystąpienie jednego zdarzenia bezpośrednio po drugim w danym śladzie. Model ten daje pogląd na zachodzący proces, jednak w wielu przypadkach może być mylący."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uZM47gjq3aLv"
   },
   "source": [
    "def draw_graph(log):\n",
    "\n",
    "  log['trace'] = [trace.split(';') for trace in  log['Activity']]\n",
    "\n",
    "  w_net = dict()\n",
    "  ev_start_set = set()\n",
    "  ev_end_set = set()\n",
    "  for index, row in log[['trace','count']].iterrows():\n",
    "    if row['trace'][0] not in ev_start_set:\n",
    "      ev_start_set.add(row['trace'][0])\n",
    "    if row['trace'][-1] not in ev_end_set:\n",
    "      ev_end_set.add(row['trace'][-1])\n",
    "    for ev_i, ev_j in pairwise(row['trace']):\n",
    "      if ev_i not in w_net.keys():\n",
    "        w_net[ev_i] = Counter()\n",
    "      w_net[ev_i][ev_j] += row['count']\n",
    "\n",
    "  G = pgv.AGraph(strict=False, directed=True)\n",
    "  G.graph_attr['rankdir'] = 'LR'\n",
    "  G.node_attr['shape'] = 'Mrecord'\n",
    "  for event, succesors in w_net.items():\n",
    "    G.add_node(event, style=\"rounded,filled\", fillcolor=\"#ffffcc\")\n",
    "    G.add_edges_from([(event, sc) for sc in succesors])\n",
    "  G.draw('simple_heuristic_net.png', prog='dot')\n",
    "  display(Image('simple_heuristic_net.png'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fvAjfWtRfq3G"
   },
   "source": [
    "Z pierwszego dziennika zdarzeń udało się otrzymać następujący graf:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 387
    },
    "id": "hsD33fqX39X1",
    "outputId": "b4e43b10-bc2e-444f-ca37-a33fcd628e89"
   },
   "source": [
    "draw_graph(log_1_routes)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6APU5r_fscY"
   },
   "source": [
    "Z drugiego dziennika zdarzeń otrzymano graf postaci:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "id": "RyQHRdnh4YC2",
    "outputId": "eea777b3-9020-47bb-9884-302640d1cd69"
   },
   "source": [
    "draw_graph(log_2_routes)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SKG1RL7Ztmtl"
   },
   "source": [
    "Aby dokładniej zobrazować proces, możemy pokolorować zadania według ich wystąpień w dzienniku zdarzeń, a także dodać odpowiednie etykiety w zależności od tego,\n",
    "jak często w logu występowało dane zdarzenie albo przepływ."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "psKkIcSb4g6f"
   },
   "source": [
    "def draw_graph(dfs, case_id, timestamp, activity):\n",
    "  ev_counter = dfs.Activity.value_counts()\n",
    "  dfs = (dfs\n",
    "      .sort_values(by=[case_id, timestamp])\n",
    "      .groupby([case_id])\n",
    "      .agg({activity: ';'.join})\n",
    "  )\n",
    "  dfs['count'] = 0\n",
    "  dfs = (\n",
    "      dfs.groupby(activity, as_index=False).count()\n",
    "      .sort_values(['count'], ascending=False)\n",
    "      .reset_index(drop=True)\n",
    "  )\n",
    "  dfs['trace'] = [trace.split(';') for trace in dfs[activity]]\n",
    "\n",
    "  w_net = dict()\n",
    "  ev_start_set = set()\n",
    "  ev_end_set = set()\n",
    "  for index, row in dfs[['trace','count']].iterrows():\n",
    "      if row['trace'][0] not in ev_start_set:\n",
    "          ev_start_set.add(row['trace'][0])\n",
    "      if row['trace'][-1] not in ev_end_set:\n",
    "          ev_end_set.add(row['trace'][-1])\n",
    "      for ev_i, ev_j in pairwise(row['trace']):\n",
    "          if ev_i not in w_net.keys():\n",
    "              w_net[ev_i] = Counter()\n",
    "          w_net[ev_i][ev_j] += row['count']\n",
    "\n",
    "  trace_counts = sorted(chain(*[c.values() for c in w_net.values()]))\n",
    "  trace_min = trace_counts[0]\n",
    "  trace_max = trace_counts[-1]\n",
    "  color_min = ev_counter.min()\n",
    "  color_max = ev_counter.max()\n",
    "\n",
    "  G = pgv.AGraph(strict= False, directed=True)\n",
    "  G.graph_attr['rankdir'] = 'LR'\n",
    "  G.node_attr['shape'] = 'Mrecord'\n",
    "\n",
    "  G.add_node(\"start\", shape=\"circle\", label=\"\")\n",
    "  for ev_start in ev_start_set:\n",
    "    G.add_edge(\"start\", ev_start)\n",
    "\n",
    "  for event, succesors in w_net.items():\n",
    "    value = ev_counter[event]\n",
    "    color = int(float(color_min-value)/float(color_min-color_max)*100.00)\n",
    "    label = str(event) + \": \" + str(ev_counter[event])\n",
    "    my_color = \"#ff9933\"+str(hex(color))[2:]\n",
    "    G.add_node(event, style=\"rounded,filled\", fillcolor=my_color, label=label)\n",
    "    for succesor, cnt in succesors.items():\n",
    "      G.add_edge(event, succesor, penwidth=4*cnt/(trace_max-trace_min)+0.1, label=cnt)\n",
    "\n",
    "  G.add_node(\"end\", shape=\"circle\", label=\"\", penwidth='3')\n",
    "  for ev_end in ev_end_set:\n",
    "    G.add_edge(ev_end, \"end\")\n",
    "\n",
    "  G.draw('simple_heuristic_net_with_events.png', prog='dot')\n",
    "  display(Image('simple_heuristic_net_with_events.png'))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "NPgPktU74jr3",
    "outputId": "b1dd823c-155e-4320-9a6b-427d570fa238"
   },
   "source": [
    "draw_graph(log_1, 'case:concept:name', 'time:timestamp', 'Activity')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 288
    },
    "id": "9DInH81I4ttP",
    "outputId": "aaf26fc8-61f3-4eef-f900-7eaeebbc32b7"
   },
   "source": [
    "draw_graph(log_2, 'Case ID', 'Start Timestamp', 'Activity')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7sZFH4z5M3O"
   },
   "source": [
    "Celem eksploracji procesów jest przekształcenie danych o zdarzeniach w schematy, będące punktem wyjścia do analizy wydajności procesów. Dane wykorzystywane w eksploracji procesu, przekazywane w postaci dzienników zdarzeń, są następnie przekształcane w pewne notacje. W celu przekształcenia dziennika zdarzeń do wybranej notacji można skorzystać z gotowego algorytmu. Do przykładowych algorytmów stosowanych w eksploracji procesów należą Alpha Miner, Inductive Miner czy Heuristic Miner. Algorytm Alpha Miner generuje model w postaci sieci Petriego, Heuristic Miner w postaci sieci Heurystycznej, natomiast za pomocą Inductive Miner można otrzymać zarówno sieć Petriego jak i drzewo procesu. Ponadto czasami możliwe jest przekonwertowanie sieci otrzymanej przez Alpha Miner bądź Heuristic Miner do postaci drzewa. Aby przekonwertować sieć Petriego pewnego procesu na drzewo procesu, konieczne jest spełnienie dwóch warunków: sieć musi być poprawna i posiadać strukturę blokową. W praktyce oznacza to, że nie wszystkie odkryte sieci procesu w postaci sieci Petriego mogą być reprezentowane jako drzewa procesu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jE6N9GqEusdN"
   },
   "source": [
    "# **Implementacja z wykorzystanie biblioteki PM4PY**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKl4XFCM6mGA"
   },
   "source": [
    "PM4Py (Process Mining for Python) to biblioteka open source służąca do analizy procesów biznesowych. Jednym z głównych obszarów funkcjonalnych tej biblioteki jest zapewnienie implementacji różnych algorytmów odkrywania procesów, w tym Alpha Miner, Heuristics Miner czy Inductive Miner. Biblioteka oferuje również narzędzia do wizualizacji, które umożliwiają tworzenie graficznych reprezentacji procesów, takich jak sieci Petriego czy drzewa procesów.\n",
    "\n",
    "[Dokumentacja PM4Py](https://pm4py.fit.fraunhofer.de/documentation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQsZbWm_J60T"
   },
   "source": [
    "### **Alpha Miner**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0iuhMwmh9l38"
   },
   "source": [
    "# EXAMPLE 1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJZ8daa0r59_"
   },
   "source": [
    "Alpha Miner jest jednym z najbardziej znanych algorytmów eksploracji procesów i jest w stanie znaleźć:\n",
    "\n",
    "* Model sieci Petriego, w którym wszystkie przejścia są widoczne i niepowtarzalne oraz odpowiadają sklasyfikowanym zdarzeniom.\n",
    "* Miejsce początkowe opisujące stan modelu sieci Petriego w momencie rozpoczęcia wykonywania.\n",
    "* Miejsce końcowe opisujące stan modelu sieci Petriego po zakończeniu wykonania.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sia82-uZ9NNr"
   },
   "source": [
    "Zwizualizujmy więc sieć Petriego na podstawie algorytmu Alpha Miner."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 470
    },
    "id": "M9yzZm858Gm5",
    "outputId": "8ae5b802-17bf-465c-9f89-67064024ff3d"
   },
   "source": [
    "net, initial_marking, final_marking = pm4py.discover_petri_net_alpha(log_1)\n",
    "\n",
    "pm4py.view_petri_net(net, initial_marking, final_marking, format=\"png\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GCxVtlN_9Rqb"
   },
   "source": [
    "Sprawdźmy czy jest możliwe przekonwertownie powyższej sieci do postaci drzewa procesu:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "id": "1l5AEBrx8rgR",
    "outputId": "f16819e1-1968-4f31-a0b5-c2bce34157f9"
   },
   "source": [
    "try:\n",
    "  tree = pm4py.convert_to_process_tree(net, initial_marking, final_marking)\n",
    "  pm4py.view_process_tree(tree)\n",
    "except ValueError:\n",
    "  print(\"Parsing of WF-net Failed\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AuhGgYIC926X"
   },
   "source": [
    "Podany dziennik zdarzeń da  się sprowadzić do postaci drzewa z wykorzystaniem algorytmu Alpha Miner."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XRtUMbAV-A2S"
   },
   "source": [
    "# EXAMPLE 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "1tcGcmD--EWU",
    "outputId": "cb023e97-36ad-48ee-9cfb-cf6f32bcba39"
   },
   "source": [
    "net, initial_marking, final_marking = pm4py.discover_petri_net_alpha(log_2)\n",
    "\n",
    "pm4py.view_petri_net(net, initial_marking, final_marking, format=\"png\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r8vRbLqT-JXO"
   },
   "source": [
    "Sprawdźmy czy jest możliwe przekonwertownie powyższej sieci do postaci drzewa procesu:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tz0ONRYl-K2x",
    "outputId": "e583ab01-b12a-4bcb-8f74-5e0a708d272c"
   },
   "source": [
    "try:\n",
    "  tree = pm4py.convert_to_process_tree(net, initial_marking, final_marking)\n",
    "  pm4py.view_process_tree(tree)\n",
    "except ValueError:\n",
    "  print(\"Parsing of WF-net Failed\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yekKrMu4-OXW"
   },
   "source": [
    "Sieć Petriego otrzymana na podstawie tego dziennika zdarzeń, w przypadku użycia algorytmu Alpha Miner nie daje sprowadzić się do drzewa procesów. Otrzymana Sieć Petriego nie jest poprawna."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pjHbVmje1-an"
   },
   "source": [
    "### **Inductive Miner**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-lovwoB-qz7"
   },
   "source": [
    "Algorytmy z tej grupy zwracają model w postaci drzewa procesu. Konwersja drzewa\n",
    "procesu w sieć procesu jest łatwo osiągalna, a uzyskana sieć jest zawsze poprawna. W ramach działania algorytmu tworzony jest graf bezpośrednich podążeń, w ramach którego dokonywany jest podział logów. W wyniku podziału powstają pod-logi, które następnie poddaje się dalszym podziałom, do momentu\n",
    "pozostania jedynie jednej aktywności. Operacja podziału logów oparta jest\n",
    "o wzorce: sekwencyjny (→), wyłącznego wyboru (×), równoległości (∧) oraz pętli (⟳). Gdy\n",
    "wzorzec zostanie rozpoznany, jego symbol umieszczany jest jako wierzchołek drzewa, a powstałe\n",
    "pod-logi umieszczane są na galęziach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lw8zvp0Cbcru"
   },
   "source": [
    "Biblioteka PM4PY umożliwia otrzymanie dwóch modeli procesów: sieci Petriego oraz drzewa.\n",
    "Aby uzyskać sieć Petriego odczytywany jest dziennik zdarzeń, nakładany jest algorytm Inductive Miner oraz odnajdywana jest sieć Petriego wraz z początkowym i końcowym oznaczeniem."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wtgKOoZQAeth"
   },
   "source": [
    "# EXAMPLE 1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "id": "NSCbD_JzAaHg",
    "outputId": "d4b6340c-5edc-4db6-97d4-0ca1aaeb6e72"
   },
   "source": [
    "net, initial_marking, final_marking = pm4py.discover_petri_net_inductive(log_1)\n",
    "\n",
    "pm4py.view_petri_net(net, initial_marking, final_marking, format=\"png\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "id": "EXi5g0OEAJRY",
    "outputId": "24273ef7-eea8-430a-ee6e-6b8b4286e015"
   },
   "source": [
    "tree_1 = pm4py.discover_process_tree_inductive(log_1)\n",
    "\n",
    "pm4py.view_process_tree(tree_1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7UdC5eyA2SP"
   },
   "source": [
    "Możemy zauważyć, że otrzymane drzewo procesu ma identyczną formę co w przypadku algorytmu Inductive Miner"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8MY-RaplATcz"
   },
   "source": [
    "# EXAMPLE 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "7YbNyCMgArvz",
    "outputId": "837b0b55-ee0f-4202-a10a-23ab2339cb6c"
   },
   "source": [
    "net, initial_marking, final_marking = pm4py.discover_petri_net_inductive(log_2)\n",
    "\n",
    "pm4py.view_petri_net(net, initial_marking, final_marking, format=\"png\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "id": "efOZm9MAAv0q",
    "outputId": "1fbe8092-9639-4470-f7bc-492bacc28946"
   },
   "source": [
    "tree_2 = pm4py.discover_process_tree_inductive(log_2)\n",
    "\n",
    "pm4py.view_process_tree(tree_2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxDGNq-kBJ_e"
   },
   "source": [
    "Biblioteka PM4Py posiada także implementacje modyfikacji algorytmu Inductive Miner - Inductive Miner infrequent. Aby skorzystać z filtracji trzeba zmienić parametr wejściowy noise_threshold z wartości domyślnej wynoszącej 0 na dowolną wartość z zakresu od 0 do 1. Parametr ten dotyczy stopnia ignorowania zakłóceń w dzienniki zdarzeń. Warto zauważyć, że gdy noise_threshold ustawiony jest na wartość 0 to wytworzony model ma stuprocentową trafność natomiast nie jest do końca precyzyjny. Zastosowanie filtracji poprzez użycie algorytmu Inductive Miner infrequent pozwala na poprawę precyzji, zachowując przy tym dość dobrą trafność."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DY_eqzZlEokH"
   },
   "source": [
    "Ponieważ drzewo procesu otrzymane dla dziennika zdarzeń log_2 ma dość skomplikowaną strukturę, postanowiono sprawdzić jak zastosowanie filtracji wpłynie na formę tego drzewa."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Dg8mLMtpBKzX"
   },
   "source": [
    "# EXAMPLE 3"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5aOvp71CXF3"
   },
   "source": [
    "Drzewo procesu dla dziennika zdarzeń log_2 przy wartości parametru progu zaszumienia wynoszącej 0.5:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 556
    },
    "id": "Otx0CqacC5-T",
    "outputId": "3c046210-a637-4a4c-e8e5-9ea64a6619c7"
   },
   "source": [
    "tree_3 = pm4py.discover_process_tree_inductive(log_2, 0.5)\n",
    "\n",
    "pm4py.view_process_tree(tree_3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "C86C7wAPCtSm"
   },
   "source": [
    "# EXAMPLE 4"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aqq06y_fCpHX"
   },
   "source": [
    "Drzewo procesu dla dziennika zdarzeń log_2 przy wartości parametru progu zaszumienia wynoszącej 1:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 460
    },
    "id": "AblR-zFUDTV2",
    "outputId": "34f8ef30-6980-4f2c-a680-22bf50a6f3a8"
   },
   "source": [
    "tree_4 = pm4py.discover_process_tree_inductive(log_2, 1)\n",
    "\n",
    "pm4py.view_process_tree(tree_4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQmmPWBVFOm0"
   },
   "source": [
    "Równoważnym zapisem powyższych drzew procesu są wyrażenia wzorcowe W następującej postaci:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DWRVLAoFFZ9Z"
   },
   "source": [
    "# EXAMPLE 1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nXv277ZgFU-H"
   },
   "source": [
    "Wyrażenie W1:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nasibezcFl5s",
    "outputId": "8053d8e7-40a7-4589-b742-f09368980e18"
   },
   "source": [
    "W1 = str(tree_1)\n",
    "print(W1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NGEo-7YnFh3Y"
   },
   "source": [
    "# EXAMPLE 2"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cixkduObFkZ0"
   },
   "source": [
    "Wyrażenie W2:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Aj1BvcTFquU",
    "outputId": "202ec018-53c5-4b6e-c305-4a2be57f1e57"
   },
   "source": [
    "W2 = str(tree_2)\n",
    "print(W2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nHDalCgKFh-w"
   },
   "source": [
    "# EXAMPLE 3"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BvzpzIAbFkvi"
   },
   "source": [
    "Wyrażenie W3:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1DNll2oFFvGu",
    "outputId": "647367e4-b6eb-4913-c3b9-3879e35fb0c4"
   },
   "source": [
    "W3 = str(tree_3)\n",
    "print(W3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oBLugLi6FiQT"
   },
   "source": [
    "# EXAMPLE 4"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fcq7xqAEFk9H"
   },
   "source": [
    "Wyrażenie W4:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gxK-jUiaFzrM",
    "outputId": "aceafe42-4b9b-429d-cb19-69b24a1ed5eb"
   },
   "source": [
    "W4 = str(tree_4)\n",
    "print(W4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WDKiNHT8Gf-P"
   },
   "source": [
    "# **Generowanie specyfikacji logicznej**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6pwOBoTUGqeC"
   },
   "source": [
    "Założeniem projektu było zaimplementowanie rozwiązania umożliwiającego automatyczne generowanie specyfikacji logicznych w oparciu o wybrane zatwierdzone wzorce przepływu oraz bezpośrednio z nimi powiązane, predefiniowane wzorce logiczne.  Jako pośredni model procesu wybrano drzewo procesu, które zostało otrzymane na podstawie dziennika zdarzeń, a etykiety drzewa posłużyły do definicji zatwierdzonych wzorców przepływu. Uzyskana specyfikacja logiczna może być następnie użyta do automatycznej weryfikacji poprawności działania systemu poprzez zastosowanie jednego z dostępnych systemów automatycznego dowodzenia twierdzeń. Takie podejście umożliwi bardziej efektywne badanie i weryfikację zachowań analizowanego systemu.\n",
    "\n",
    "Stworzony system składa się z 4 elementów:\n",
    "\n",
    "\n",
    "1.   Generator drzewa procesu (generator wyrażeń W przedstawiony wyżej)\n",
    "2.   Konwerter wzorców z drzewa procesu do zatwierdzonych wzorców przepływu\n",
    "3.   Predefiniowane wzorce logiczne\n",
    "4.   Algorytm konwertujący drzewo procesu do postaci specyfikacji logicznej\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xzaK4JOXVtcB"
   },
   "source": [
    "### **Konwersja wzorców z drzewa procesu do zatwierdzonych wzorców przepływu**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cKZp0Gk3pOrl"
   },
   "source": [
    "**ProcessTreeAdapter**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hbdgAtRAH2Sf"
   },
   "source": [
    "class ProcessTreeAdapter:\n",
    "\n",
    "    @staticmethod\n",
    "    def remove_brackets_between_single_quotes(expression):\n",
    "        pattern = r\"'(.*?)'\"\n",
    "        matches = re.findall(pattern, expression)\n",
    "\n",
    "        for match in matches:\n",
    "            replaced = match.replace('(', '').replace(')', '')\n",
    "            expression = expression.replace(f\"'{match}'\", f\"'{replaced}'\")\n",
    "        return expression\n",
    "\n",
    "    @staticmethod\n",
    "    def label_expressions(expression: str) -> str:\n",
    "        labelled_expression = \"\"\n",
    "        label_number = 0\n",
    "        for c in expression:\n",
    "            if c == '(':\n",
    "                label_number += 1\n",
    "                labelled_expression += f\"({label_number}]\"\n",
    "            elif c == ')':\n",
    "                labelled_expression += f\"[{label_number})\"\n",
    "                label_number -= 1\n",
    "            else:\n",
    "                labelled_expression += c\n",
    "        return labelled_expression\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_arguments_from_labelled_expression(labelled_expression):\n",
    "        pattern_label_number = int(labelled_expression[-2])\n",
    "        trimmed_labelled_expression = labelled_expression[labelled_expression.index(\"]\") + 1:-3]\n",
    "        split = trimmed_labelled_expression.split(\",\")\n",
    "        arguments = []\n",
    "        brackets_counter = 0\n",
    "        temp_arg = \"\"\n",
    "        for s in split:\n",
    "            brackets_counter += s.count('(')\n",
    "            brackets_counter -= s.count(')')\n",
    "            temp_arg += s + \",\"\n",
    "            if brackets_counter == 0:\n",
    "                temp_arg = temp_arg[:-1]\n",
    "                arguments.append(temp_arg)\n",
    "                temp_arg = \"\"\n",
    "        return arguments, pattern_label_number\n",
    "\n",
    "    @staticmethod\n",
    "    def find_symbol(labelled_expression):\n",
    "        pattern = r'^[^()]*'\n",
    "        match = re.match(pattern, labelled_expression)\n",
    "        if match:\n",
    "            return re.sub(r'\\s+', '', match.group())\n",
    "        else:\n",
    "            raise Exception(\"No match\")\n",
    "\n",
    "    @staticmethod\n",
    "    def replace_spaces_with_underscore(tree):\n",
    "        def replace_spaces(match):\n",
    "            return re.sub(r'\\s+', '_', match.group(0))\n",
    "\n",
    "        text_with_underscore = re.sub(r\"'(.*?)'\", replace_spaces, tree)\n",
    "        text_no_quotes = re.sub(r\"'\", '', text_with_underscore)\n",
    "\n",
    "        return text_no_quotes\n",
    "\n",
    "    @staticmethod\n",
    "    def replace_symbol_with_name(labelled_pattern_expression, pattern_label_number, old_symbol, new_name):\n",
    "        pattern = rf\"{re.escape(old_symbol)}\\(({pattern_label_number}\\])\"\n",
    "        new_name = new_name + \"(\" + str(pattern_label_number) + \"]\"\n",
    "        replaced_string = re.sub(pattern, new_name, labelled_pattern_expression)\n",
    "\n",
    "        return replaced_string\n",
    "\n",
    "    @staticmethod\n",
    "    def get_highest_label(labelledExpression: str) -> int:\n",
    "        maxLabel = -1\n",
    "        active = False\n",
    "        sb = \"\"\n",
    "        for c in labelledExpression:\n",
    "            if c == '(':\n",
    "                active = True\n",
    "            elif c == ']':\n",
    "                if int(sb) > maxLabel:\n",
    "                    maxLabel = int(sb)\n",
    "                sb = \"\"\n",
    "                active = False\n",
    "            elif active:\n",
    "                sb += c\n",
    "        return maxLabel"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mn4vNFtcLDLn"
   },
   "source": [
    "**Usunięcie nawisów okrągłych w nazwach czynności**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1H8F5iYLLQ5P"
   },
   "source": [
    "W1 = ProcessTreeAdapter.remove_brackets_between_single_quotes(W1)\n",
    "W2 = ProcessTreeAdapter.remove_brackets_between_single_quotes(W2)\n",
    "W3 = ProcessTreeAdapter.remove_brackets_between_single_quotes(W3)\n",
    "W4 = ProcessTreeAdapter.remove_brackets_between_single_quotes(W4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "O1kijAqnLjgh",
    "outputId": "a6d334d1-ff34-4618-bc07-7dbb5fd00b2d"
   },
   "source": [
    "print(W1)\n",
    "print(W2)\n",
    "print(W3)\n",
    "print(W4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2P33UDYVIzly"
   },
   "source": [
    "**Zamiana spacji na podkreślnik w nazwach czynności**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6poGEHwAMBMX"
   },
   "source": [
    "W1 = ProcessTreeAdapter.replace_spaces_with_underscore(W1)\n",
    "W1 = W1.replace(\"( \", \"(\").replace(\") \", \")\").replace(\" )\", \")\").replace(\"->\", \">\")\n",
    "\n",
    "W2 = ProcessTreeAdapter.replace_spaces_with_underscore(W2)\n",
    "W2 = W2.replace(\"( \", \"(\").replace(\") \", \")\").replace(\" )\", \")\").replace(\"->\", \">\")\n",
    "\n",
    "W3 = ProcessTreeAdapter.replace_spaces_with_underscore(W3)\n",
    "W3 = W3.replace(\"( \", \"(\").replace(\") \", \")\").replace(\" )\", \")\").replace(\"->\", \">\")\n",
    "\n",
    "W4 = ProcessTreeAdapter.replace_spaces_with_underscore(W4)\n",
    "W4 = W4.replace(\"( \", \"(\").replace(\") \", \")\").replace(\" )\", \")\").replace(\"->\", \">\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Her7Mx2AMU9B",
    "outputId": "3296de12-61e9-45b4-ce89-674a99f04dbf"
   },
   "source": [
    "print(W1)\n",
    "print(W2)\n",
    "print(W3)\n",
    "print(W4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLjJ1Q52IrVq"
   },
   "source": [
    "**Numerowanie zagnieżdżeń**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8Y_huQFFKe94"
   },
   "source": [
    "labelled_pattern_expression1 = ProcessTreeAdapter.label_expressions(W1)\n",
    "labelled_pattern_expression2 = ProcessTreeAdapter.label_expressions(W2)\n",
    "labelled_pattern_expression3 = ProcessTreeAdapter.label_expressions(W3)\n",
    "labelled_pattern_expression4 = ProcessTreeAdapter.label_expressions(W4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hs3hLu9nMmE4",
    "outputId": "1a542473-88c2-4575-a348-68e974a10c83"
   },
   "source": [
    "print(labelled_pattern_expression1)\n",
    "print(labelled_pattern_expression2)\n",
    "print(labelled_pattern_expression3)\n",
    "print(labelled_pattern_expression4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7DbzrBWMz-g"
   },
   "source": [
    "**Zmiana etykiet drzewa procesu na zatwierdzone wzorce przepływu**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TasOu5c8NHCl"
   },
   "source": [
    "W oparciu o etykiety występujące w drzewie procesu (czy też wyrażeniu W) oraz ilość zadań podlegających pod każdą z tych etykiet, zdefiniowano następujący zestaw zatwierdzonych wzorców przepływu:\n",
    "\n",
    "Σ = {Seq2, Seq3, Seq4, Seq5, Xor2, Xor3, And2, And3, Loop}\n",
    "\n",
    "Każda z etykiet wzorców występujących w wyrażeniu W tj. ->, X, +, * zostaje zamieniona na nazwę odpowiadającego jej zatwierdzonego wzorca przepływu."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vl4A5ffPNGj2"
   },
   "source": [
    "class Sequence:\n",
    "    @staticmethod\n",
    "    def change_symbol_into_name(labelled_expression):\n",
    "        pattern_symbol = '>'\n",
    "        pattern_name = 'Seq'\n",
    "        if len(labelled_expression) == 2:\n",
    "            pattern_name = 'Seq2'\n",
    "        elif len(labelled_expression) == 3:\n",
    "            pattern_name = 'Seq3'\n",
    "        elif len(labelled_expression) == 4:\n",
    "            pattern_name = 'Seq4'\n",
    "        elif len(labelled_expression) == 5:\n",
    "            pattern_name = 'Seq5'\n",
    "        else:\n",
    "            raise Exception(\"pattern does not exist\")\n",
    "        return pattern_name\n",
    "\n",
    "class Loop:\n",
    "    @staticmethod\n",
    "    def change_symbol_into_name(labelled_expression, pattern_label_number):\n",
    "        pattern_symbol = '*'\n",
    "        pattern_name = 'Loop'\n",
    "        labelled_expression_to_replace = \"(\" + str(pattern_label_number) + \"]\" + \",\".join(labelled_expression) + \"[\" + str(pattern_label_number) + \")\"\n",
    "        if len(labelled_expression) == 2:\n",
    "            labelled_expression = ['l_s'] + labelled_expression\n",
    "        else:\n",
    "            raise Exception(\"pattern does not exist\")\n",
    "        new_labelled_expression = \"(\" + str(pattern_label_number) + \"]\" + \",\".join(labelled_expression) + \"[\" + str(pattern_label_number) + \")\"\n",
    "        return pattern_name, labelled_expression_to_replace, new_labelled_expression\n",
    "\n",
    "class ExclusiveChoice:\n",
    "    @staticmethod\n",
    "    def change_symbol_into_name(labelled_expression, pattern_label_number):\n",
    "        pattern_symbol = 'X'\n",
    "        pattern_name = 'Xor'\n",
    "        labelled_expression_to_replace = \"(\" + str(pattern_label_number) + \"]\" + \",\".join(labelled_expression) + \"[\" + str(pattern_label_number) + \")\"\n",
    "        if len(labelled_expression) == 2:\n",
    "            pattern_name = 'Xor2'\n",
    "            labelled_expression = ['x2_s'] + labelled_expression + ['x2_e']\n",
    "        elif len(labelled_expression) == 3:\n",
    "            pattern_name = 'Xor3'\n",
    "            labelled_expression = ['x3_s'] + labelled_expression + ['x3_e']\n",
    "        else:\n",
    "            raise Exception(\"pattern does not exist\")\n",
    "        new_labelled_expression = \"(\" + str(pattern_label_number) + \"]\" + \",\".join(labelled_expression) + \"[\" + str(pattern_label_number) + \")\"\n",
    "        return pattern_name, labelled_expression_to_replace, new_labelled_expression\n",
    "\n",
    "class Parallelism:\n",
    "    @staticmethod\n",
    "    def change_symbol_into_name(labelled_expression, pattern_label_number):\n",
    "        pattern_symbol = '+'\n",
    "        pattern_name = 'And'\n",
    "        labelled_expression_to_replace = \"(\" + str(pattern_label_number) + \"]\" + \",\".join(labelled_expression) + \"[\" + str(pattern_label_number) + \")\"\n",
    "        if len(labelled_expression) == 2:\n",
    "            pattern_name = 'And2'\n",
    "            labelled_expression = ['a2_s'] + labelled_expression + ['a2_e']\n",
    "        elif len(labelled_expression) == 3:\n",
    "            pattern_name = 'And3'\n",
    "            labelled_expression = ['a3_s'] + labelled_expression + ['a3_e']\n",
    "        else:\n",
    "            raise Exception(\"pattern does not exist\")\n",
    "        new_labelled_expression = \"(\" + str(pattern_label_number) + \"]\" + \",\".join(labelled_expression) + \"[\" + str(pattern_label_number) + \")\"\n",
    "        return pattern_name, labelled_expression_to_replace, new_labelled_expression\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G0wQ8VrJhpFe"
   },
   "source": [
    "**PatternExpressionGenerator**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_D5fXCxTOeqZ"
   },
   "source": [
    "class PatternExpressionGenerator:\n",
    "    def __init__(self, converted_expression):\n",
    "        self.converted_expression = converted_expression\n",
    "\n",
    "    def add_approved_workflow_patterns(self, expression):\n",
    "          if expression == None or isinstance(expression , list):\n",
    "            return\n",
    "\n",
    "          symbol = ProcessTreeAdapter.find_symbol(expression)\n",
    "          pattern = r'>|X|\\+|\\*'\n",
    "          matches = re.findall(pattern, expression)\n",
    "\n",
    "          if (len(matches) != 0):\n",
    "            arguments = ProcessTreeAdapter.extract_arguments_from_labelled_expression(expression)\n",
    "            expression = arguments[0]\n",
    "            pattern_label_number = arguments[1]\n",
    "            if symbol == '>':\n",
    "                new_name = Sequence.change_symbol_into_name(expression)\n",
    "                self.converted_expression = ProcessTreeAdapter.replace_symbol_with_name(self.converted_expression, pattern_label_number, symbol, new_name)\n",
    "            elif symbol == '*':\n",
    "                new_name = Loop.change_symbol_into_name(expression, pattern_label_number)\n",
    "                self.converted_expression = ProcessTreeAdapter.replace_symbol_with_name(self.converted_expression, pattern_label_number, symbol, new_name[0])\n",
    "                expression_to_replace = self.converted_expression\n",
    "                self.converted_expression = expression_to_replace.replace(new_name[1], new_name[2])\n",
    "            elif symbol == '+':\n",
    "                new_name = Parallelism.change_symbol_into_name(expression, pattern_label_number)\n",
    "                self.converted_expression = ProcessTreeAdapter.replace_symbol_with_name(self.converted_expression, pattern_label_number, symbol, new_name[0])\n",
    "\n",
    "                expression_to_replace = self.converted_expression\n",
    "                self.converted_expression = expression_to_replace.replace(new_name[1], new_name[2])\n",
    "            elif symbol == 'X':\n",
    "                new_name = ExclusiveChoice.change_symbol_into_name(expression, pattern_label_number)\n",
    "                self.converted_expression = ProcessTreeAdapter.replace_symbol_with_name(self.converted_expression, pattern_label_number, symbol, new_name[0])\n",
    "                expression_to_replace = self.converted_expression\n",
    "                self.converted_expression = expression_to_replace.replace(new_name[1], new_name[2])\n",
    "            else:\n",
    "                raise Exception(\"pattern does not exist\")\n",
    "          return expression\n",
    "\n",
    "    def get_converted_expression(self):\n",
    "        return self.converted_expression\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_sKnrO5JWgCD"
   },
   "source": [
    "def process_patterns(pattern_list, instance):\n",
    "    new_pattern_list = []\n",
    "    for pattern in pattern_list:\n",
    "        new_pattern = instance.add_approved_workflow_patterns(pattern)\n",
    "        if isinstance(new_pattern, list):\n",
    "            new_pattern = process_patterns(new_pattern, instance)\n",
    "        new_pattern_list.append(new_pattern)\n",
    "    return new_pattern_list\n",
    "\n",
    "def recursive_process(pattern_list, instance, depth):\n",
    "    if depth <= 0:\n",
    "        return pattern_list\n",
    "    else:\n",
    "        pattern_list = process_patterns(pattern_list, instance)\n",
    "        return recursive_process(pattern_list, instance, depth - 1)\n",
    "\n",
    "def get_pattern_expression(labelled_pattern_expression):\n",
    "    pattern_list = []\n",
    "    pattern_list.append(labelled_pattern_expression)\n",
    "    pattern_expression_generator = PatternExpressionGenerator(labelled_pattern_expression)\n",
    "    recursive_process(pattern_list, pattern_expression_generator, ProcessTreeAdapter.get_highest_label(labelled_pattern_expression))\n",
    "\n",
    "    return pattern_expression_generator.get_converted_expression()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6ma1ZC5JZLTx"
   },
   "source": [
    "pattern_expression1 = get_pattern_expression(labelled_pattern_expression1)\n",
    "pattern_expression2 = get_pattern_expression(labelled_pattern_expression2)\n",
    "pattern_expression3 = get_pattern_expression(labelled_pattern_expression3)\n",
    "pattern_expression4 = get_pattern_expression(labelled_pattern_expression4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qhZ58k9hhAnA",
    "outputId": "48ebb18d-3743-476d-988e-c217ad30a51e"
   },
   "source": [
    "print(pattern_expression1)\n",
    "print(pattern_expression2)\n",
    "print(pattern_expression3)\n",
    "print(pattern_expression4)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gf7kPRAOh-OB"
   },
   "source": [
    "### **Predefiniowane wzorce logiczne**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HpPZ8l9AiI1-"
   },
   "source": [
    "Dla wszystkich zatwierdzonych wzorców przepływu wyznaczono bezpośrednio z nimi powiązane, predefiniowane wzorce logiczne.\n",
    "Zbiór predefiniowanych wzorców logicznych został zawarty w pliku konfiguracyjnym o nazwie **approved_patterns.json**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0do-xw-WZi77"
   },
   "source": [
    "**WorkflowPatternTemplate**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RIJmM9loYPAR"
   },
   "source": [
    "class WorkflowPatternTemplate:\n",
    "    def __init__(self, name, number_of_arguments, rules):\n",
    "        self.name = name\n",
    "        self.number_of_arguments = number_of_arguments\n",
    "        self.rules = rules\n",
    "\n",
    "    @staticmethod\n",
    "    def load_pattern_property_set(path_to_pattern_rules_file):\n",
    "        with open(path_to_pattern_rules_file, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            pattern_property_set = []\n",
    "            for workflow_pattern_template_name, pattern_descr_json_object in data.items():\n",
    "                number_of_arguments = pattern_descr_json_object[\"number of args\"]\n",
    "                rules = pattern_descr_json_object[\"rules\"]\n",
    "                workflow_pattern_template = WorkflowPatternTemplate(workflow_pattern_template_name, number_of_arguments, rules)\n",
    "                pattern_property_set.append(workflow_pattern_template)\n",
    "            return pattern_property_set\n",
    "\n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "\n",
    "    def set_name(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def get_number_of_arguments(self):\n",
    "        return self.number_of_arguments\n",
    "\n",
    "    def set_number_of_arguments(self, number_of_arguments):\n",
    "        self.number_of_arguments = number_of_arguments\n",
    "\n",
    "    def get_rules(self):\n",
    "        return self.rules\n",
    "\n",
    "    def set_rules(self, rules):\n",
    "        self.rules = rules\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5uNYyc9ZVHM"
   },
   "source": [
    "**WorkflowPattern**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_mPVtpDOjSmx"
   },
   "source": [
    "class WorkflowPattern:\n",
    "    def __init__(self, workflow_pattern_template, pattern_arguments):\n",
    "        self.workflow_pattern_template = workflow_pattern_template\n",
    "        self.pattern_arguments = pattern_arguments\n",
    "\n",
    "    @staticmethod\n",
    "    def get_workflow_pattern_from_expression(pattern_expression, pattern_property_set):\n",
    "        workflow_name = pattern_expression[:pattern_expression.index(\"(\")]\n",
    "        workflow_pattern_template = next((template for template in pattern_property_set if template.get_name() == workflow_name), None)\n",
    "\n",
    "        if workflow_pattern_template is None:\n",
    "            raise Exception(\"Workflow pattern template not found!\")\n",
    "        pattern_arguments = WorkflowPattern.extract_arguments_from_labelled_expression(pattern_expression, pattern_property_set)\n",
    "        return WorkflowPattern(workflow_pattern_template, pattern_arguments)\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_arguments_from_labelled_expression(labelled_expression, pattern_property_set):\n",
    "        workflow_name = labelled_expression[:labelled_expression.index(\"(\")]\n",
    "        workflow_pattern_template = next((template for template in pattern_property_set if template.get_name() == workflow_name), None)\n",
    "        if workflow_pattern_template is None:\n",
    "            raise Exception(\"Workflow pattern template not found!\")\n",
    "\n",
    "        number_of_arguments = workflow_pattern_template.get_number_of_arguments()\n",
    "        pattern_label_number = int(labelled_expression[-2])\n",
    "        trimmed_labelled_expression = labelled_expression[labelled_expression.index(\"]\") + 1:-3]\n",
    "        split = trimmed_labelled_expression.split(\",\")\n",
    "        arguments = []\n",
    "        brackets_counter = 0\n",
    "        temp_arg = \"\"\n",
    "        for s in split:\n",
    "            brackets_counter += s.count('(')\n",
    "            brackets_counter -= s.count(')')\n",
    "            temp_arg += s + \",\"\n",
    "            if brackets_counter == 0:\n",
    "                temp_arg = temp_arg[:-1]\n",
    "                arguments.append(temp_arg)\n",
    "                temp_arg = \"\"\n",
    "\n",
    "        if len(arguments) != number_of_arguments:\n",
    "            raise Exception(f\"Found arguments ({arguments}) different from the required number ({number_of_arguments})\")\n",
    "        return arguments\n",
    "\n",
    "    @staticmethod\n",
    "    def count_occurrence_of_char(string, char):\n",
    "        return string.count(char)\n",
    "\n",
    "    @staticmethod\n",
    "    def is_not_atomic(argument):\n",
    "        return \"=>\" in argument or \"|\" in argument or \"^\" in argument or \"]\" in argument\n",
    "\n",
    "    def get_workflow_pattern_template(self):\n",
    "        return self.workflow_pattern_template\n",
    "\n",
    "    def set_workflow_pattern_template(self, workflow_pattern_template):\n",
    "        self.workflow_pattern_template = workflow_pattern_template\n",
    "\n",
    "    def get_workflow_pattern_filled_rules(self):\n",
    "        if len(self.pattern_arguments) > 0:\n",
    "            outcomes = []\n",
    "            for outcome in self.workflow_pattern_template.get_rules():\n",
    "                outcome_with_params = outcome\n",
    "                for i, arg in enumerate(self.pattern_arguments):\n",
    "                    outcome_with_params = outcome_with_params.replace(\"arg\" + str(i), arg)\n",
    "                outcomes.append(outcome_with_params)\n",
    "            return outcomes\n",
    "        else:\n",
    "            raise Exception(\"No arguments for the given pattern in the expression\")\n",
    "\n",
    "    def get_pattern_arguments(self):\n",
    "        return self.pattern_arguments\n",
    "\n",
    "    def set_pattern_arguments(self, pattern_arguments):\n",
    "        self.pattern_arguments = pattern_arguments\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "K_FpH1qcocu6"
   },
   "source": [
    "pattern_rules= \"/content/approved_patterns.json\"\n",
    "ltl_pattern_property_set = WorkflowPatternTemplate.load_pattern_property_set(pattern_rules)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "udXHQG5DjRsE"
   },
   "source": [
    "### **Algorytm konwertujący drzewo procesu do postaci specyfikacji logicznej**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MbccwYSnjfcx"
   },
   "source": [
    "Zaimplementowany algorytm został opisany w artykule:\n",
    "\n",
    "[R. Klimek, Pattern-based and composition-driven automatic generation of logical specifications for workflow-oriented\n",
    "software models](https://www.sciencedirect.com/science/article/pii/S2352220818300889)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXNDjZYhYQPd"
   },
   "source": [
    "**CalculatingConsolidatedExpression**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OsMsyuqoj50J"
   },
   "source": [
    "from typing import List\n",
    "\n",
    "class CalculatingConsolidatedExpression:\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_consolidated_expression(pattern_expression: str, expression_type: str, pattern_property_set: List[WorkflowPatternTemplate]) -> str:\n",
    "\n",
    "        if expression_type not in (\"ini\", \"fin\"):\n",
    "            raise Exception(\"type must equal 'ini' or 'fin'!\")\n",
    "\n",
    "        ex = \"\"\n",
    "        workflow_pattern = WorkflowPattern.get_workflow_pattern_from_expression(pattern_expression, pattern_property_set)\n",
    "        rules_with_atomic_activities = workflow_pattern.get_workflow_pattern_filled_rules()\n",
    "        ini = rules_with_atomic_activities[0]\n",
    "        fin = rules_with_atomic_activities[1]\n",
    "        rules_with_atomic_activities = rules_with_atomic_activities[2:]\n",
    "\n",
    "        if expression_type == \"ini\":\n",
    "            ex = ini\n",
    "        else:\n",
    "            ex = fin\n",
    "\n",
    "        expression_arguments = WorkflowPattern.extract_arguments_from_labelled_expression(pattern_expression, pattern_property_set)\n",
    "        for argument in expression_arguments:\n",
    "            if WorkflowPattern.is_not_atomic(argument):\n",
    "                inner_consolidated_expression = CalculatingConsolidatedExpression.generate_consolidated_expression(argument, expression_type, pattern_property_set)\n",
    "\n",
    "                ex = ex.replace(argument, inner_consolidated_expression)\n",
    "        return ex\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ux82wW8JYxb0"
   },
   "source": [
    "**GeneratingLogicalSpecifications**\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ONwOGBUakRSA"
   },
   "source": [
    "from typing import List\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "class GeneratingLogicalSpecifications:\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_logical_specifications(pattern_expression: str, pattern_property_set: List[WorkflowPatternTemplate]) -> str:\n",
    "        logical_specification = []\n",
    "        labelled_expression = pattern_expression\n",
    "        highest_label_number = ProcessTreeAdapter.get_highest_label(labelled_expression)\n",
    "        for l in range(highest_label_number, 0, -1):\n",
    "            c = 1\n",
    "            pat = GeneratingLogicalSpecifications.get_pat(labelled_expression, l, c, pattern_property_set)\n",
    "            while pat is not None:\n",
    "                L2 = pat.get_workflow_pattern_filled_rules()\n",
    "                L2 = L2[2:]\n",
    "                for arg in pat.get_pattern_arguments():\n",
    "                    if WorkflowPattern.is_not_atomic(arg):\n",
    "                        cons = CalculatingConsolidatedExpression.generate_consolidated_expression(arg, \"ini\", pattern_property_set) + \" | \" + CalculatingConsolidatedExpression.generate_consolidated_expression(arg, \"fin\", pattern_property_set)\n",
    "                        L2_cons = [outcome.replace(arg, cons) for outcome in L2]\n",
    "                        L2 = L2_cons\n",
    "                c += 1\n",
    "                logical_specification.extend(L2)\n",
    "                pat = GeneratingLogicalSpecifications.get_pat(labelled_expression, l, c, pattern_property_set)\n",
    "\n",
    "        logical_specification = list(set(logical_specification))\n",
    "        connected_string = \"\"\n",
    "        print(\"\\nWynik: \")\n",
    "        for l_value in logical_specification:\n",
    "            connected_string += l_value + \", \"\n",
    "            print(l_value)\n",
    "        return connected_string\n",
    "\n",
    "    @staticmethod\n",
    "    def get_pat(labelled_expression: str, l: int, c: int, pattern_property_set: List[WorkflowPatternTemplate]) -> WorkflowPattern:\n",
    "        entry_occurrences = labelled_expression.count(\"(\" + str(l) + \"]\")\n",
    "        end_occurrences = labelled_expression.count(\"[\" + str(l) + \")\")\n",
    "        if entry_occurrences != end_occurrences:\n",
    "            raise Exception(\"(\" + str(l) + \"] nie równa się [\" + str(l) + \")\")\n",
    "\n",
    "        if entry_occurrences < c:\n",
    "            return None\n",
    "\n",
    "        expression_split_by_entry = re.split(rf\"\\({l}\\]\", labelled_expression)\n",
    "        pattern_content = re.split(rf\"\\[{l}\\)\", expression_split_by_entry[c])[0]\n",
    "        split_by_bracket = re.split(r\"\\]\", expression_split_by_entry[c - 1])\n",
    "        workflow_name = re.split(r\",\", split_by_bracket[-1])[-1]\n",
    "        workflow_exp = workflow_name + f\"({l}]\" + pattern_content + f\"[{l})\"\n",
    "        return WorkflowPattern.get_workflow_pattern_from_expression(workflow_exp, pattern_property_set)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JigAuJCvYMJe"
   },
   "source": [
    "**Wygenerowana specyfikacja**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kU-6h5oblQjj"
   },
   "source": [
    "def get_results(pattern_expression):\n",
    "    print(pattern_expression)\n",
    "\n",
    "    ini = CalculatingConsolidatedExpression.generate_consolidated_expression(pattern_expression.replace(\" \", \"\"), \"ini\", ltl_pattern_property_set)\n",
    "    print(\"ini: \" + ini)\n",
    "    fin = CalculatingConsolidatedExpression.generate_consolidated_expression(pattern_expression.replace(\" \", \"\"), \"fin\", ltl_pattern_property_set)\n",
    "    print(\"fin: \" + fin)\n",
    "\n",
    "    GeneratingLogicalSpecifications.generate_logical_specifications(pattern_expression.replace(\" \", \"\"), ltl_pattern_property_set)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zCWeVUJIqQ7q",
    "outputId": "5e33fa1d-abf3-43d0-83e5-c988318bb665"
   },
   "source": [
    "# EXAMPLE 1\n",
    "\n",
    "get_results(pattern_expression1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S60bazKkqVHs",
    "outputId": "a811f255-9fc2-4da4-c1a3-3920da980be9"
   },
   "source": [
    "# EXAMPLE 2\n",
    "\n",
    "get_results(pattern_expression2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZeSuqPBWqVej",
    "outputId": "0839c208-7c14-40f7-a61c-3680b821fe3f"
   },
   "source": [
    "# EXAMPLE 3\n",
    "\n",
    "get_results(pattern_expression3)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mSfkVlzBqVsx",
    "outputId": "4ce7ac7f-2ac5-4521-d26e-4fa4191cd922"
   },
   "source": [
    "# EXAMPLE 4\n",
    "\n",
    "get_results(pattern_expression4)"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "name": "python3",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
